{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Text_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "K_L0nyebXEG-",
        "0r7XC-BgXEG_"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CICxgqXEDiP0"
      },
      "source": [
        "# Auto Text Generation using TensorFlow\n",
        "## Generating Text with an RNN (Recurrent Neural Network)\n",
        "\n",
        "Recurrent Neural Networks (RNN) are a class of neural networks that is powerful for modeling sequence data such as time series or natural language.\n",
        "\n",
        "An RNN works like this; First words get transformed into machine-readable vectors. Then the RNN processes the sequence of vectors one by one.\n",
        "\n",
        "\n",
        "\n",
        "<div class=\"alert alert-box alert-warning\">\n",
        "Use the following links to go back to the different parts of this exercise that require to modify the function `nnCostFunction`.<br>\n",
        "\n",
        "Back to:\n",
        "- [Dataset Preparation](#section1)\n",
        "- [Process the text](#section2)\n",
        "- [Generating Sequence of N-gram Tokens (Word Embeddings)](#section4)\n",
        "- [Padding the Sequences and obtain Variables: Predictors and Target](#section5)\n",
        "- [LSTM for Text Generation](#Section6)\n",
        "- [Generating the text](#section7)\n",
        "</div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxhNB_zmQiV-",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/1400/1*AQ52bwW55GsJt6HTxPDuMA.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wh91Gc7ZklEZ"
      },
      "source": [
        "Enable GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lAGohGF4k3Nx",
        "outputId": "a586771c-9907-4e90-ca63-0d2ce91ba70c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OH-MpWwYkquR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "61AQnVrylIYr"
      },
      "source": [
        "Check GPU Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iQSqSyQ3k9Fw",
        "outputId": "d1a982cc-def4-4802-ac6b-bbbeb809e111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.667116954999983\n",
            "GPU (s):\n",
            "0.05741041599998198\n",
            "GPU speedup over CPU: 63x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6pqx_zoWl3R9"
      },
      "source": [
        "Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eZqwIbEHDiP1",
        "outputId": "3ebb88a4-8cff-4aa8-f744-86629cac9e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# keras module for building LSTM \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "\n",
        "# set seeds for reproducability\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1234) \n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xiQU9M0AmiuO"
      },
      "source": [
        "Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IBjwx9BFD3a6",
        "outputId": "e91f8e27-d0d1-4612-ab29-8c85c288c917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "woincU83D3Ym",
        "outputId": "426ceca7-808d-4bd2-f25c-4f7f27cf308b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sfM0cyB6D3TA",
        "outputId": "94d33f50-a2d1-4877-f332-387d3d701f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GXKR7bsvD3P5",
        "outputId": "1aabb374-a29c-4778-d698-f6b703006c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "irusLcmJD3Nh",
        "outputId": "cd3fe9a7-3e86-4355-ecf5-4359a5b99b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/ML"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ML\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t0k7RiByEIAY",
        "outputId": "f17537ce-ae72-496d-cc64-bff979775eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ArticlesApril2017.csv  ArticlesJan2017.csv    ArticlesMay2017.csv\n",
            "ArticlesApril2018.csv  ArticlesJan2018.csv    Headline.ipynb\n",
            "ArticlesFeb2017.csv    ArticlesMarch2017.csv  TextGenerator.ipynb\n",
            "ArticlesFeb2018.csv    ArticlesMarch2018.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "edanNgBADiP8",
        "colab": {}
      },
      "source": [
        "ArticleJan17 = pd.read_csv('ArticlesJan2017.csv')\n",
        "ArticleFeb17 = pd.read_csv('ArticlesFeb2017.csv')\n",
        "ArticleMar17 = pd.read_csv('ArticlesMarch2017.csv')\n",
        "ArticleApr17 = pd.read_csv('ArticlesApril2017.csv')\n",
        "ArticleMay17 = pd.read_csv('ArticlesMay2017.csv')\n",
        "ArticleJan18 = pd.read_csv('ArticlesJan2018.csv')\n",
        "ArticleFeb18 = pd.read_csv('ArticlesFeb2018.csv')\n",
        "ArticleMar18 = pd.read_csv('ArticlesMarch2018.csv')\n",
        "ArticleApr18 = pd.read_csv('ArticlesApril2018.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LUl25wQxDiP_",
        "colab": {}
      },
      "source": [
        "article_df = pd.concat([ArticleJan17 ,ArticleFeb17 ,ArticleMar17 ,ArticleApr17 ,ArticleMay17 ,ArticleJan18 , ArticleFeb18, ArticleMar18, ArticleApr18], sort = False);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gpXginVqDiQB",
        "outputId": "07893126-f736-494f-b359-30cf950b78ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "article_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleID</th>\n",
              "      <th>abstract</th>\n",
              "      <th>byline</th>\n",
              "      <th>documentType</th>\n",
              "      <th>headline</th>\n",
              "      <th>keywords</th>\n",
              "      <th>multimedia</th>\n",
              "      <th>newDesk</th>\n",
              "      <th>printPage</th>\n",
              "      <th>pubDate</th>\n",
              "      <th>sectionName</th>\n",
              "      <th>snippet</th>\n",
              "      <th>source</th>\n",
              "      <th>typeOfMaterial</th>\n",
              "      <th>webURL</th>\n",
              "      <th>articleWordCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58691a5795d0e039260788b9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>By JENNIFER STEINHAUER</td>\n",
              "      <td>article</td>\n",
              "      <td>G.O.P. Leadership Poised to Topple Obama’s Pi...</td>\n",
              "      <td>['United States Politics and Government', 'Law...</td>\n",
              "      <td>1</td>\n",
              "      <td>National</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-01-01 15:03:38</td>\n",
              "      <td>Politics</td>\n",
              "      <td>The most powerful and ambitious Republican-led...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2017/01/01/us/politics...</td>\n",
              "      <td>1324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>586967bf95d0e03926078915</td>\n",
              "      <td>NaN</td>\n",
              "      <td>By MARK LANDLER</td>\n",
              "      <td>article</td>\n",
              "      <td>Fractured World Tested the Hope of a Young Pre...</td>\n",
              "      <td>['Obama, Barack', 'Afghanistan', 'United State...</td>\n",
              "      <td>1</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>1</td>\n",
              "      <td>2017-01-01 20:34:00</td>\n",
              "      <td>Asia Pacific</td>\n",
              "      <td>A strategy that went from a “good war” to the ...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2017/01/01/world/asia/...</td>\n",
              "      <td>2836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>58698a1095d0e0392607894a</td>\n",
              "      <td>NaN</td>\n",
              "      <td>By CAITLIN LOVINGER</td>\n",
              "      <td>article</td>\n",
              "      <td>Little Troublemakers</td>\n",
              "      <td>['Crossword Puzzles', 'Boxing Day', 'Holidays ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Games</td>\n",
              "      <td>0</td>\n",
              "      <td>2017-01-01 23:00:24</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Chuck Deodene puts us in a bubbly mood.</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2017/01/01/crosswords/...</td>\n",
              "      <td>445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5869911a95d0e0392607894e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>By JOCHEN BITTNER</td>\n",
              "      <td>article</td>\n",
              "      <td>Angela Merkel, Russia’s Next Target</td>\n",
              "      <td>['Cyberwarfare and Defense', 'Presidential Ele...</td>\n",
              "      <td>1</td>\n",
              "      <td>OpEd</td>\n",
              "      <td>15</td>\n",
              "      <td>2017-01-01 23:30:27</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>With a friend entering the White House, Vladim...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>Op-Ed</td>\n",
              "      <td>https://www.nytimes.com/2017/01/01/opinion/ang...</td>\n",
              "      <td>864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5869a61795d0e03926078962</td>\n",
              "      <td>NaN</td>\n",
              "      <td>By JIAYIN SHEN</td>\n",
              "      <td>article</td>\n",
              "      <td>Boots for a Stranger on a Bus</td>\n",
              "      <td>['Shoes and Boots', 'Buses', 'New York City']</td>\n",
              "      <td>0</td>\n",
              "      <td>Metro</td>\n",
              "      <td>12</td>\n",
              "      <td>2017-01-02 01:00:02</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Witnessing an act of generosity on a rainy day.</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>Brief</td>\n",
              "      <td>https://www.nytimes.com/2017/01/01/nyregion/me...</td>\n",
              "      <td>309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  articleID  ... articleWordCount\n",
              "0  58691a5795d0e039260788b9  ...             1324\n",
              "1  586967bf95d0e03926078915  ...             2836\n",
              "2  58698a1095d0e0392607894a  ...              445\n",
              "3  5869911a95d0e0392607894e  ...              864\n",
              "4  5869a61795d0e03926078962  ...              309\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zCV0bvYUDiQE",
        "outputId": "15f74990-b147-48e7-94fa-7a927275a1da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "article_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9335, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2DXZTgqgDiQH",
        "outputId": "14f49a24-31f8-4955-d1ea-f7299cd8c6f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ML\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y5zpitJ6nPIT"
      },
      "source": [
        "# **Dataset preparation**\n",
        "##Dataset Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_K1w0FyJnS2V"
      },
      "source": [
        "1. Perform text cleaning of the data which includes removal of punctuations\n",
        "2. Lower casing all the words\n",
        "3. Remove HTML tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vXhTmAh6DiQL",
        "outputId": "cf1bd193-e859-4145-acb3-ce544ff0ddf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "curr_dir = '../ML/'\n",
        "headline = []\n",
        "for filename in os.listdir(curr_dir):\n",
        "    if 'Articles' in filename:\n",
        "        article_df = pd.concat([ArticleJan17 ,ArticleFeb17 ,ArticleMar17 ,ArticleApr17 ,ArticleMay17 ,ArticleJan18 , ArticleFeb18, ArticleMar18, ArticleApr18], sort = False);\n",
        "        headline.extend(list(article_df.headline.values))\n",
        "        break\n",
        "\n",
        "headline = [h for h in headline if h != \"Unknown\"]\n",
        "len(headline)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jTLAPh5QnCMT"
      },
      "source": [
        "**A corpus** is a large collection of text, and in the machine learning sense a corpus can be thought of as your model's input data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x5qKfvKWDiQO",
        "outputId": "fe0ef5a9-2721-4442-8bd5-4bf0118b108b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "def clean_text(text):\n",
        "    text = \"\".join(v for v in text if v not in string.punctuation).lower()\n",
        "    text = text.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return text \n",
        "\n",
        "corpus = [clean_text(x) for x in headline]\n",
        "corpus[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' gop leadership poised to topple obamas pillars',\n",
              " 'fractured world tested the hope of a young president',\n",
              " 'little troublemakers',\n",
              " 'angela merkel russias next target',\n",
              " 'boots for a stranger on a bus',\n",
              " 'molder of navajo youth where a game is sacred',\n",
              " 'the affair season 3 episode 6 noah goes home',\n",
              " 'sprint and mr trumps fictional jobs',\n",
              " 'america  becomes a stan',\n",
              " 'fighting diabetes and leading by example']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpJ-PS3fnugi",
        "outputId": "26bdd7a5-38bf-46e5-bca9-c270d62bdcab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(string.punctuation)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DEPI0nH8orqC"
      },
      "source": [
        "Look into the Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0CZZQPY5nuTv"
      },
      "source": [
        "Using the function \"clean_text\", below string gets converted to lower case with no punctuation or tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K7ObIq4Tosqd",
        "outputId": "e7d02761-8ddd-478a-d085-4ebfafff5cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(corpus)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 8603 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X8qLxzgFowwo"
      },
      "source": [
        "Take a look into the first 250 characters in text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sfe_G-T0o0Qc",
        "outputId": "b4c75692-10de-4c75-aad1-454545318a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(corpus[:250])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' gop leadership poised to topple obamas pillars', 'fractured world tested the hope of a young president', 'little troublemakers', 'angela merkel russias next target', 'boots for a stranger on a bus', 'molder of navajo youth where a game is sacred', 'the affair season 3 episode 6 noah goes home', 'sprint and mr trumps fictional jobs', 'america  becomes a stan', 'fighting diabetes and leading by example', 'chinese court says mr c was fired unjustifiably', 'cold therapy maybe better save your money', 'shunned stars of steroid era are on deck for cooperstown', 'picking up a personal thread at an office party', 'health reform could outlast repeal efforts', 'mr trump bureaucracy apprentice', 'house gop votes to gut an office reviewing ethics', 'right to disconnect from work email and other laws go into effect in france', 'lessons from the tea party', 'all talk', 'winter comforts', 'the snapchat presidency', 'the house at the end of the world', 'power down', 'fraud culture rises in india aiming at us', 'new york today new year new commute', 'the year of conquering negativity', 'questions for leave your laptops at the door to my classroom', 'what are your predictions for 2017', 'is your workout not working', 'house gop abandons bid to stifle ethics office', 'pregnancy preeclampsia and eye trouble', 'a fox news pillars jump to nbc will test her and the networks', 'wishful thinkers', 'arms  and  the trump', 'leicester city learns magic goes only so far', 'to evaluate a dogs smarts humans pick up new tricks', 'a second empire by trumps side', 'a little variety', 'major changes loom for corporate taxes', 'variety acrostic', 'russians mock meddling charge as unsupported', 'how to starve online hate', 'crime and gratitude in new york', 'white house red scare', 'the war that killed trust', 'yes its your parents fault', 'for the forgotten africanamerican dead', 'the future of the times a view from the top', 'the downsizing of nathaniel ames', 'a bond over bucking the establishment', 'la la land dominates with record wins', 'fury in mexicos streets after gas prices surge', 'failure to comb', 'allstar defendant  both soon on a plaque', 'the grim reaper of alabama', 'a secret squadron agent at the pushcart', 'what are you hiding jeff sessions', 'for assange a 10year vision of toppling power is a reality', 'strikes by russia  buttress turkey  in battle vs isis', 'you only turn 40 one time', 'the affair season 3 episode 7 theres a monster in the basement', 'when a beast awakens the giants go into hibernation', 'deficits  matter  again', 'is humanism really humane', 'erasing president obama', 'michelle obamas turn', 'the age  of fake  policy', 'the home buying decision', 'dabbing in congress', 'questions for indias callcenter talents put to a criminal use swindling americans', 'how should opponents receive the new president  with an open mind and honor for the office or with defiance and rejection', 'how the qing court sowed the seeds of environmental protection in china', 'friday mailbag taunts hoaxes anonymity and stealth', 'year of  the renter', 'teaching with midnight three  six', 'grabbing card bonuses before banks pull them', 'the japanese art of grieving a miscarriage', 'as trump denies climate change these kids die', 'some assembly required but worth it', 'putin led scheme to aid trump report says', 'rumors of hillary clintons comeback', 'jobs well done how obama compares with predecessors', 'agreement would close indian point nuclear power plant by 2021', 'trumps anticia crusade', 'into a world of fantasy where the sorcerers take center stage', 'the dangers of safety equipment', 'giving mr trumps nominees a pass', 'instagram explore', 'a middle eastern layer cake for dinner', 'swan song', 'every extra penny counts', 'on inauguration marching band takes a stand', 'is singlesex education still useful', 'body anemia tied to hearing loss', 'new york today becoming a new yorker', 'from a fateful motorcade a view of an american divide', 'socialmedia rules created by kids', 'feed children peanuts early doctors advise', 'to predict gentrification look for falling crime', 'the motto that won out', 'chocolate found to stave off death analyzing the scientific evidence behind health headlines', 'paraguay and venezuela together at the table', 'packers playoff miseries as memorable as any title', 'is your cocktail making you sick', 'bipartisan voices back us agencies on russia hacking', 'first comes love then mortality', 'strangers in an audience healing one another', '3 new jersey lawmakers feel shortchanged by port authoritys 10year plan', 'skunks in the city', 'might clinton run against de blasio an unlikely idea has people talking', 'department stores once anchors at malls become millstones', 'mr trump casts intelligence aside', 'numbers game', 'whos really limiting free speech', 'trump and the tainted  presidency', 'what to watch for in washington confirmation hearings and trump meeting the press', 'where homelessness can be a crime', 'whats going on in this picture  jan 9 2017', 'curbing our digital dependence', 'new york reveals deal to close a nuclear plant', 'how emotion over pet care helps explain human health spending', 'do you watch hollywood awards ceremonies', 'after playoff loss giants hope theyre only young once', 'a slower pace for the galloping gourmet', 'believe it or not a fifa plan that could benefit the game', 'soninlaw is set to be key adviser in trump office', 'womens march opens a raw dialogue on race', 'what the soldiers and sailors may have seen', 'left behind at a bus stop but not for long', 'cuomo raises profile stirring talk of 20 run', 'vw executives trip let fbi pounce', 'discflipper', 'clemson stops time and tide', 'dancers in masks', 'bannon  vs trump', 'the dnc hack was just the start', 'republican hypocrisy on trumps nominees', 'the fight for health care has begun', 'big worries about betsy devos', 'questions for a month without sugar', 'fifa to expand the world cup and its coffers', 'should we trash cash', 'what will you remember about president obama and his legacy', 'cover story', 'the list', 'new york today whats next for the rockefeller center christmas tree', 'its streep  vs trump  for america', 'weekly news quiz  jan 19 2017', 'title is a surprise but not to clemson', 'prisons for profit may cost society', 'not she said he said mockery plain and simple', 'fox news paid oreilly accuser to keep quiet', 'leadership from top not here', 'rye rises again', 'flavor with an artistic bent', 'seven questions about repealing obamacare', 'pregnancy heartburn drugs and asthma', 'gifts from dad', 'trump was told of claims russia has damaging details on him', 'thats what you get for putting your sneakers in the dryer', 'pillar of yankees seems an afterthought for the hall', 'not in a knot', 'offbeat interests', 'online  and scared', 'kellyannes dark magic', 'republican dissension on obamacare', 'my life with paralysis its a workout', 'a fix for gender bias in health care check', 'questions for on being a black female math whiz during the space race', 'sue fulton thinks equal rights make the military stronger', 'what should i do about a physician who may be a quack', 'how good is your sense of direction', 'us and them', 'how to be mindful by the fire', 'weekend warriors live longer', 'new york today central parks newest wheels', 'economists worry about trump and their relevance', 'britains left turn  to a dead end for social democracy', 'partisanship is the real story behind the fake news', 'a family trust for businesses may fall short', 'talking with both daughters and sons about sex', 'whats the difference between the national debt and the federal deficit', 'door opens to hinterlands of soccer', 'looking to tune in to catch womens tennis for now better get creative', 'former attorney general to lead an attack on republican gerrymandering', 'cancer mammograms downside', 'text to text comparing jewish refugees of the 1930s with syrian refugees today', 'mind diet may help the brain', 'the glare varies for two actors', 'finding redemption in a second banana', 'the coming health care crisis', 'stock figure', 'questions for when water balloons hit a bed of nails and dont pop', 'in your head', 'the antiinauguration', 'what does your party want', 'the gop  health  hoax', 'why rural america voted for trump', 'trump reality politics', 'china rates the best toilets for tourists and tells the laggards to clean up', 'the sketch guys most valued lessons still sting how about yours', 'seeing america through ngel francos eyes', 'senate gop opens fight  over obama health law', 'being back in black  in a white snowscape', 'a modern manchurian candidate', 'ode to obama', 'bold promise hard to keep on health act', 'old men', 'trump sex and lots  of whining', 'a day of dodges and distractions donald trumps madefortv promises', 'able to handle any kind of pressure', 'how things typically are', 'device addiction', 'silicon valley takes a right turn', 'a website peddling girls for sex', 'giving up sex to give blood', 'a chance to meet and to forgive', '2016 in charts and can trump deliver in 2017', 'tantrum on the no 2', 'trump signals readiness for battle over trade', 'house fires at ethics and shoots self', 'open many doors', 'personal touch proves a winning one', 'why vera rubin deserved a nobel', 'a bipartisan reason to save obamacare', 'from hands to heads  to hearts', 'the necessity of the filibuster', 'fascinating animals', 'in turkey fingers point at americans after nearly every crisis', 'chinese media chides trump on twitter foreign policy', 'questions for congress returns republicans are in charge 6 things to watch', 'michael eric dyson believes in individual reparations', 'can i out my exhusband to his girlfriend', 'expecting trouble california picks up some legal muscle', 'the bomb', 'frightful but not invincible', 'a fitness downside to statin drugs', 'its probably safe to ignore stockbuying advice for 2017', 'for republicans an unexpected rebuke', 'new york today januarys obscure holidays', 'how to have a mindful new year', 'and the winners are ', 'why men dont want  jobs done mostly by women', 'italy leans toward truly homegrown pastas', 'is it possible for a writer to be objective', 'here to serve and to soothe', 'trumps disastrous example', 'if you could ask the times editor a question   ', 'circling the block for better fast food']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kqQToJ0To6xk"
      },
      "source": [
        "Unique characters in the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "36qXbV2Ho8LK",
        "outputId": "4dadaf02-ada6-4ac5-87d5-181f65ed50a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = sorted(set(corpus))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8309 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y2rFu4WqpDwj"
      },
      "source": [
        "#**Process the text**\n",
        "##**Generating Sequence of N-gram Tokens**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wugCT_CRpDKO"
      },
      "source": [
        "\n",
        "Tokenization\n",
        "Tokenization is a process of extracting tokens from a corpus. \n",
        "After this step, every text document in the dataset is converted into sequence of tokens.\n",
        "\n",
        "Function to predict the next word based on the input words\n",
        "\n",
        "- Tokenize the text\n",
        "- Pad the sequences\n",
        "- Pass into the trained model to get predicted word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aHPFAFloDiQQ",
        "outputId": "e9d802e5-9a65-43f4-dde8-17d5a7b38732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    \n",
        "    ## convert data to sequence of tokens \n",
        "    seq = []\n",
        "    for row in corpus:\n",
        "        tokens = tokenizer.texts_to_sequences([row])[0]\n",
        "        for i in range(1, len(tokens)):\n",
        "            n_gram_sequence = tokens[:i+1]\n",
        "            seq.append(n_gram_sequence)\n",
        "    return seq, total_words\n",
        "\n",
        "seq, total_words = get_sequence_of_tokens(corpus)\n",
        "seq[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[77, 1951],\n",
              " [77, 1951, 1360],\n",
              " [77, 1951, 1360, 3],\n",
              " [77, 1951, 1360, 3, 3366],\n",
              " [77, 1951, 1360, 3, 3366, 1601],\n",
              " [77, 1951, 1360, 3, 3366, 1601, 1952],\n",
              " [5166, 86],\n",
              " [5166, 86, 3367],\n",
              " [5166, 86, 3367, 1],\n",
              " [5166, 86, 3367, 1, 349]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R1f2JIu7rLF4",
        "outputId": "92be0e38-96ea-40df-814d-b63ce0c4f6e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(corpus[:10]), seq[:10]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' gop leadership poised to topple obamas pillars', 'fractured world tested the hope of a young president', 'little troublemakers', 'angela merkel russias next target', 'boots for a stranger on a bus', 'molder of navajo youth where a game is sacred', 'the affair season 3 episode 6 noah goes home', 'sprint and mr trumps fictional jobs', 'america  becomes a stan', 'fighting diabetes and leading by example'] ---- characters mapped to int ---- > [[77, 1951], [77, 1951, 1360], [77, 1951, 1360, 3], [77, 1951, 1360, 3, 3366], [77, 1951, 1360, 3, 3366, 1601], [77, 1951, 1360, 3, 3366, 1601, 1952], [5166, 86], [5166, 86, 3367], [5166, 86, 3367, 1], [5166, 86, 3367, 1, 349]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zafmUE53rKeQ"
      },
      "source": [
        "##**Padding the Sequences and obtain Variables: Predictors and Target**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G20KNvoLsiQy"
      },
      "source": [
        "- A data-set with sequence of tokens is generated\n",
        "- These different sequences have different lengths\n",
        "- Pad the sequences before training the model to make their lengths equal \n",
        "- There is built-in 'pad_sequence' function of Kears for this purpose \n",
        "- Predictors and label are created to input data into a learning model\n",
        "- Create N-grams sequence as predictors and the next word of the N-gram as label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lhP7b9GnDiQS",
        "colab": {}
      },
      "source": [
        "def generate_padded_sequences(seq):\n",
        "    max_length = max([len(x) for x in seq])\n",
        "    seq = np.array(pad_sequences(seq, maxlen=max_length, padding='pre'))\n",
        "    \n",
        "    predictors, label = seq[:,:-1],seq[:,-1]\n",
        "    label = ku.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_length\n",
        "\n",
        "predictors, label, max_length = generate_padded_sequences(seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Agi0fbwRsqfN"
      },
      "source": [
        "Now we can obtain the input vector X and the label vector Y which can be used for the training purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q2OfthwPswUH"
      },
      "source": [
        "## LSTM for Text Generation\n",
        "Quick Background\n",
        "\n",
        "- LSTM: Long short-term memory are a building unit for layers of a recurrent neural network (RNN). \n",
        "- A RNN composed of LSTM units is often called an LSTM network. \n",
        "- A common LSTM unit is composed of \n",
        "  - a cell\n",
        "  - an input gate, \n",
        "  - an output gate and \n",
        "  - a forget gate.\n",
        "\n",
        "1) Cell State: The long-term memory is usually called the cell state. The looping arrows indicate recursive nature of the cell.\n",
        "\n",
        "2) Forget Gate: The remember vector is usually called the forget gate. The output of the forget gate tells the cell state which information to forget by multiplying 0 to a position in the matrix. If the output of the forget gate is 1, the information is kept in the cell state.\n",
        "\n",
        "3) Input Gate: The save vector is usually called the input gate. These gates determine which information should enter the cell state / long-term memory.\n",
        "\n",
        "4) Output Gate: The focus vector is usually called the output gate.\n",
        "\n",
        "The working memory is usually called the hidden state. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M8Ibf0xis5CG"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/542/1*ULozye1lfd-dS9RSwndZdw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vt1meOid2iXU"
      },
      "source": [
        "Explanation of the algorithm\n",
        "- The idea is to train the RNN with many sequences of words and the target next_word. \n",
        "example\n",
        "- If each sentence is a list of five words, then the target is a list of only one element, indicating which is the following word in the original text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFBmkUOxEzjC",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/1400/1*n-IgHZM5baBUjq0T7RYDBw.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqZlJQr7PUlT",
        "colab_type": "text"
      },
      "source": [
        "Run this model for 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ed4d8W7BDiQU",
        "outputId": "d64c14fc-a2f6-4115-a372-41c89c884447",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "def create_model(max_length, total_words):\n",
        "    length = max_length - 1\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Add Input Embedding Layer\n",
        "    model.add(Embedding(total_words, 10, input_length=length))\n",
        "    \n",
        "    # Add Hidden Layer 1 - LSTM Layer\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.1))\n",
        "    \n",
        "    # Add Output Layer\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model(max_length, total_words)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 23, 10)            112650    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               44400     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 11265)             1137765   \n",
            "=================================================================\n",
            "Total params: 1,294,815\n",
            "Trainable params: 1,294,815\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SB31Fbbi37Un"
      },
      "source": [
        "##**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jCQBAfKWDiQX",
        "outputId": "8534c8ba-4a95-432b-93a5-ac4d2de619a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(predictors, label, epochs=100, verbose=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fc83bc50358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "po9tfOcw4DVr"
      },
      "source": [
        "## Generating the text\n",
        "\n",
        "Function to predict the next word based on the input words \n",
        "1. Tokenize the text\n",
        "2. pad the sequences  \n",
        "3. pass into the trained model to get predicted word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vQ9C8t6zDiQZ",
        "colab": {}
      },
      "source": [
        "def generate_text(seed_text, next_words, model, max_length):\n",
        "    for _ in range(next_words):\n",
        "        #tokenize the text\n",
        "        tokens = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        #pad the sequence\n",
        "        tokens = pad_sequences([tokens], maxlen=max_length-1, padding='pre')\n",
        "        #pass into the trained model to get the predicted word\n",
        "        predict = model.predict_classes(tokens, verbose=0)\n",
        "        \n",
        "        result = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == predict:\n",
        "                result = word\n",
        "                break\n",
        "        seed_text += \" \"+result\n",
        "    return seed_text.title()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWl69DgFSdn_",
        "colab_type": "text"
      },
      "source": [
        "Some Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8SnrkS5TDiQc",
        "colab": {}
      },
      "source": [
        "print (generate_text(\"united states\", 5, model, max_length))\n",
        "print (generate_text(\"preident trump\", 4, model, max_length))\n",
        "print (generate_text(\"donald trump\", 4, model, max_length))\n",
        "print (generate_text(\"india and china\", 8, model, max_length))\n",
        "print (generate_text(\"new york\", 4, model, max_length))\n",
        "print (generate_text(\"science and technology\", 5, model, max_length))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "grJT1595DiQl",
        "outputId": "89824079-a180-4a01-8ece-c900a7d11484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_text(\"world\", 4, model, max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'World Capital Inquiry To Win'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kqKDsXaeegyj",
        "outputId": "2653faaa-d571-41f4-ac90-375ddd9c23ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_text(\"population\", 4, model, max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Population The Walking Dead Season'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FbdqKKRrejv4",
        "outputId": "425ae25c-6d14-4a52-b4b1-97d13b7324ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_text(\"strange\", 4, model, max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Strange Pension Math Leaves States'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REO7b1GVen4J",
        "outputId": "5d7198e8-fd60-4816-ce78-312b805ac89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_text(\"boots\", 6, model, max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Boots For A Stranger In A Bus'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jAfRrtvfeszk",
        "outputId": "da873ac9-de62-42b2-81fd-397423266789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_text(\"how\", 4, model, max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How To Be Mindful While'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mKCP5Tu7e6Si",
        "outputId": "efae5d59-6c13-46d4-e1db-17bd35f481a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_text(\"silicon valley\", 4, model, max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Silicon Valley Wary Of Trump Warms'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qwCbqWkoe_ZJ",
        "outputId": "ce2dbdea-05d4-4fea-f741-c243ba9e1357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_text(\"sound\", 6, model, max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sound Barriers The Shape Of The Hacks'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lSphl-DKfEst",
        "outputId": "f323597b-bde0-45d7-d127-7b69d0ebbca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_text(\"Pie\", 4, model, max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pie Forges Is A Mountain'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JCcO46YDfG24",
        "outputId": "73c44277-7082-4c3b-f961-4bf0db09d4b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generate_text(\"When do you\", 5, model, max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'When Do You Want To See The Way'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WbvEMygvfyCU",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wPr4PeYwbC1Y"
      },
      "source": [
        "# Part 2: Training Markov Chain Model on NYT Comments using markovify and spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4julzWrAXEGW",
        "colab_type": "text"
      },
      "source": [
        "### This is an attempt to make a bot comment meaningfully by generating comments similar to those on the NYT articles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73I-1BiZXEGW",
        "colab_type": "text"
      },
      "source": [
        "1. 'markovify' is used for Markov chain generator for the automated text generation. \n",
        "2. NLP package spaCy is used for parts of speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CR0ncxduRIYS",
        "outputId": "28fa6bb1-a611-411d-a3e7-1889dc27b4ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "pip install -U spacy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (46.4.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wx6N6_JqRIV3",
        "outputId": "5299f48a-d442-476a-adbc-cdd8a1298a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "pip install markovify"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting markovify\n",
            "  Downloading https://files.pythonhosted.org/packages/de/c3/2e017f687e47e88eb9d8adf970527e2299fb566eba62112c2851ebb7ab93/markovify-0.8.0.tar.gz\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 4.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.8.0-cp36-none-any.whl size=10694 sha256=fd54a72f4dceeff570ac1fa128fba206ecdaf96ddd37d0e9e38df548871ba543\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/a8/92/35e2df870ff15a65657679dca105d190ec3c854a9f75435e40\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.8.0 unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zJfDBIe37zk9"
      },
      "source": [
        "These libraries are mainly used for building Markov models of large corpora of text and generating random sentences from that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFfjvukTXEGb",
        "colab_type": "text"
      },
      "source": [
        "Loading required packages and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bi2U1HlPLjcf",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import markovify \n",
        "import spacy\n",
        "import re\n",
        "from time import time\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gTjZB739VTzg",
        "outputId": "f3d4e562-3a50-4582-c069-2330849fdabf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BBtm7AZ9VTxC",
        "outputId": "ca7aaffd-b035-4fdb-c71a-251cea01823d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aU060VTmVTuz",
        "outputId": "ce32a444-fc4f-4372-8d9d-49f3a8dea08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ItiM29K4VTr2",
        "outputId": "fb0d971b-216e-40d2-eeb4-59a00faf700c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/MLFINAL"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MLFINAL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XMR4na38VTpY",
        "outputId": "db5da5d0-539f-49b6-f2b0-b3e8b8b2761e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bot.ipynb              CommentsFeb2018.csv    CommentsMarch2018.csv\n",
            "CommentsApril2017.csv  CommentsJan2017.csv    CommentsMay2017.csv\n",
            "CommentsApril2018.csv  CommentsJan2018.csv    stackText.ipynb\n",
            "CommentsFeb2017.csv    CommentsMarch2017.csv  Text.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbSzZx6MXEGp",
        "colab_type": "text"
      },
      "source": [
        "## Steps to perform:\n",
        "### 1. Prepare text from comments for training the generator.\n",
        "### 2. Training a simple Markov chain generator using the comments' text and using it to generate comments.\n",
        "### 3. Training an improved Markov chain generator with POS-Tagged text and using it to generate more comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZjMcR_ZiRHNE",
        "outputId": "fe26bccf-e291-4961-e9cc-9a7f9182aa74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "curr_dir = '../MLFINAL/'\n",
        "df1 = pd.read_csv(curr_dir + 'CommentsJan2017.csv')\n",
        "df2 = pd.read_csv(curr_dir + 'CommentsFeb2017.csv')\n",
        "df3 = pd.read_csv(curr_dir + 'CommentsMarch2017.csv')\n",
        "df4 = pd.read_csv(curr_dir + 'CommentsApril2017.csv')\n",
        "df5 = pd.read_csv(curr_dir + 'CommentsMay2017.csv')\n",
        "df6 = pd.read_csv(curr_dir + 'CommentsJan2018.csv')\n",
        "df7 = pd.read_csv(curr_dir + 'CommentsFeb2018.csv')\n",
        "df8 = pd.read_csv(curr_dir + 'CommentsMarch2018.csv')\n",
        "df9 = pd.read_csv(curr_dir + 'CommentsApril2018.csv')\n",
        "comments = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9])\n",
        "comments.drop_duplicates(subset='commentID', inplace=True)\n",
        "comments.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>approveDate</th>\n",
              "      <th>articleID</th>\n",
              "      <th>articleWordCount</th>\n",
              "      <th>commentBody</th>\n",
              "      <th>commentID</th>\n",
              "      <th>commentSequence</th>\n",
              "      <th>commentTitle</th>\n",
              "      <th>commentType</th>\n",
              "      <th>createDate</th>\n",
              "      <th>depth</th>\n",
              "      <th>editorsSelection</th>\n",
              "      <th>inReplyTo</th>\n",
              "      <th>newDesk</th>\n",
              "      <th>parentID</th>\n",
              "      <th>parentUserDisplayName</th>\n",
              "      <th>permID</th>\n",
              "      <th>picURL</th>\n",
              "      <th>printPage</th>\n",
              "      <th>recommendations</th>\n",
              "      <th>recommendedFlag</th>\n",
              "      <th>replyCount</th>\n",
              "      <th>reportAbuseFlag</th>\n",
              "      <th>sectionName</th>\n",
              "      <th>sharing</th>\n",
              "      <th>status</th>\n",
              "      <th>timespeople</th>\n",
              "      <th>trusted</th>\n",
              "      <th>updateDate</th>\n",
              "      <th>userDisplayName</th>\n",
              "      <th>userID</th>\n",
              "      <th>userLocation</th>\n",
              "      <th>userTitle</th>\n",
              "      <th>userURL</th>\n",
              "      <th>typeOfMaterial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1483455908</td>\n",
              "      <td>58691a5795d0e039260788b9</td>\n",
              "      <td>1324.0</td>\n",
              "      <td>For all you Americans out there --- still rejo...</td>\n",
              "      <td>20969730.0</td>\n",
              "      <td>20969730.0</td>\n",
              "      <td>&lt;br/&gt;</td>\n",
              "      <td>comment</td>\n",
              "      <td>1.483426e+09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>National</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20969730</td>\n",
              "      <td>https://graphics8.nytimes.com/images/apps/time...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Politics</td>\n",
              "      <td>0</td>\n",
              "      <td>approved</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1483455908</td>\n",
              "      <td>N. Smith</td>\n",
              "      <td>64679318.0</td>\n",
              "      <td>New York City</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1483455656</td>\n",
              "      <td>58691a5795d0e039260788b9</td>\n",
              "      <td>1324.0</td>\n",
              "      <td>Obamas policies may prove to be the least of t...</td>\n",
              "      <td>20969325.0</td>\n",
              "      <td>20969325.0</td>\n",
              "      <td>&lt;br/&gt;</td>\n",
              "      <td>comment</td>\n",
              "      <td>1.483417e+09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>National</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20969325</td>\n",
              "      <td>https://graphics8.nytimes.com/images/apps/time...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Politics</td>\n",
              "      <td>0</td>\n",
              "      <td>approved</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1483455656</td>\n",
              "      <td>Kilocharlie</td>\n",
              "      <td>69254188.0</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1483455655</td>\n",
              "      <td>58691a5795d0e039260788b9</td>\n",
              "      <td>1324.0</td>\n",
              "      <td>Democrats are comprised of malcontents who gen...</td>\n",
              "      <td>20969855.0</td>\n",
              "      <td>20969855.0</td>\n",
              "      <td>&lt;br/&gt;</td>\n",
              "      <td>comment</td>\n",
              "      <td>1.483431e+09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>National</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20969855</td>\n",
              "      <td>https://graphics8.nytimes.com/images/apps/time...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Politics</td>\n",
              "      <td>0</td>\n",
              "      <td>approved</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1483455655</td>\n",
              "      <td>Frank Fryer</td>\n",
              "      <td>76788711.0</td>\n",
              "      <td>Florida</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>News</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   approveDate                 articleID  ...  userURL typeOfMaterial\n",
              "0   1483455908  58691a5795d0e039260788b9  ...      NaN           News\n",
              "1   1483455656  58691a5795d0e039260788b9  ...      NaN           News\n",
              "2   1483455655  58691a5795d0e039260788b9  ...      NaN           News\n",
              "\n",
              "[3 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6BSMRHAMRHVK",
        "outputId": "8938b610-5dc6-49f2-e16c-e66d900be337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "comments.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2118617, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4KqH-Gd1L-bD",
        "outputId": "9851cd44-9596-427a-9a79-6622a4b99ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "comments.sectionName.value_counts()[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unknown          1096761\n",
              "Politics          479701\n",
              "Sunday Review     143849\n",
              "Europe             46844\n",
              "Middle East        32385\n",
              "Name: sectionName, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEwq8hWPXEGw",
        "colab_type": "text"
      },
      "source": [
        "Politics has more number of articles so let's select \"Politics\" as our section Name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TAwX0K2WWaiA",
        "colab": {}
      },
      "source": [
        "def preprocess(comments):\n",
        "    commentBody = comments.loc[comments.sectionName=='Politics', 'commentBody']\n",
        "    commentBody = commentBody.str.replace(\"(<br/>)\", \"\")\n",
        "    commentBody = commentBody.str.replace('(<a).*(>).*(</a>)', '')\n",
        "    commentBody = commentBody.str.replace('(&amp)', '')\n",
        "    commentBody = commentBody.str.replace('(&gt)', '')\n",
        "    commentBody = commentBody.str.replace('(&lt)', '')\n",
        "    commentBody = commentBody.str.replace('(\\xa0)', ' ')  \n",
        "    return commentBody"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_77KbGIBV9hX",
        "outputId": "817de7dc-9583-4aa6-f92b-c1a87153cbfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "commentBody = preprocess(comments)\n",
        "commentBody.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(479701,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q07arqDHV_de",
        "outputId": "1a41f1d0-54e0-498c-b193-15a9925e065e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "del comments, df1, df2, df3, df4, df5, df6, df7, df8\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqUbceSyXEG4",
        "colab_type": "text"
      },
      "source": [
        "A Sample comment present on the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G4CeeTojWeyD",
        "outputId": "198256f8-c65a-47e9-bf9f-3a5ea4f41b8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "commentBody.sample().values[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Both parties need to come to an agreement to limit budget talks to one or at most, two C.R.'s. Continuing to kick the can down the road plays havoc with the lives of millions of families and effectively limits discussion on any other issues because budget talks are always in a crisis mode.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSkHJxY2XEG5",
        "colab_type": "text"
      },
      "source": [
        "### How it works?\n",
        "The Markov chain generator focuses on the current word and randomly find the next word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SbCeuXHIWhpT",
        "outputId": "5493656d-75a7-4b6d-94a3-b17dc92482d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "start_time = time()\n",
        "comments_generator = markovify.Text(commentBody, state_size = 5)\n",
        "print(\"Run time for training the generator : {} seconds\".format(round(time()-start_time, 2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run time for training the generator : 79.15 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGhOB_GdXEG7",
        "colab_type": "text"
      },
      "source": [
        "Print randomly-generated comments using the built model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8y4mKvQrW60e",
        "colab": {}
      },
      "source": [
        "def generate_comments(generator, number=10, short=False):\n",
        "    count = 0\n",
        "    while count < number:\n",
        "        if short:\n",
        "            comment = generator.make_short_sentence(140)\n",
        "        else:\n",
        "            comment = generator.make_sentence()\n",
        "        if comment:\n",
        "            count += 1\n",
        "            print(\"Comment {}\".format(count))\n",
        "            print(comment)\n",
        "            print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_L0nyebXEG-",
        "colab_type": "text"
      },
      "source": [
        "### Comments generated by Bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cMDY7rPJXYWs",
        "outputId": "044afc61-5c95-48a2-f55e-ff3b1d409873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "generate_comments(comments_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comment 1\n",
            "I don't know how to tell the truth.\n",
            "\n",
            "Comment 2\n",
            "Thanks to all of you and to the The New York Times for its slanted coverage favoring Hillary over Trump.\n",
            "\n",
            "Comment 3\n",
            "Dems and sane republicans should get to the bottom of this... just like the republicans did for Benghazi.\n",
            "\n",
            "Comment 4\n",
            "Some day these Republican members of Congress will do nothing as long as they have been properly licensed and register the weapon.\n",
            "\n",
            "Comment 5\n",
            "Donald Trump has not hidden the fact that he is the most persecuted innocent man in the world since Job.\n",
            "\n",
            "Comment 6\n",
            "Again, it is obvious Trump does not understand he is a public servant, not the dictator he believes he is.\n",
            "\n",
            "Comment 7\n",
            "Mind you, it will take a generation of young people to begin by saying NO! to the current system.\n",
            "\n",
            "Comment 8\n",
            "Of course Trump would have to still be president to be able to vent and rant behind closed doors with his aides.\n",
            "\n",
            "Comment 9\n",
            "The corruption is so deep, someone needs to step up to the plate now and put country before party.\n",
            "\n",
            "Comment 10\n",
            "I find this president frightening, but I have no idea what agency or branch of government publishes the forms.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r7XC-BgXEG_",
        "colab_type": "text"
      },
      "source": [
        "### Improving Markov chain generator using spaCy for POS-Tagging:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VvvtWnoXEHA",
        "colab_type": "text"
      },
      "source": [
        "Improving sentence structure by using parts of speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lmHokYsVXae7",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en\")\n",
        "\n",
        "class POSifiedText(markovify.Text):\n",
        "    def word_split(self, sentence):\n",
        "        return [\"::\".join((word.orth_, word.pos_)) for word in nlp(sentence)]\n",
        "\n",
        "    def word_join(self, words):\n",
        "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\n",
        "        return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWvOhxusXEHB",
        "colab_type": "text"
      },
      "source": [
        "- POS-Tagging somewhat slows down the training of the generator model\n",
        "- Use a smaller training set consisting of comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qfQUDqPXXvhb",
        "outputId": "cad863bc-eaad-4270-daae-3b86f868e90b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "commentBody = preprocess(df9)\n",
        "commentBody.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58818,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IafTqFfWXxZX",
        "outputId": "48d0f91c-1b7c-4462-fef6-0bacef9213c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "del comments_generator, df9\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LpibXJSQXzR6",
        "outputId": "1e7e3d4f-d369-45d9-e39d-9c66839705ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "start_time = time()\n",
        "comments_generator_POSified = POSifiedText(commentBody, state_size = 2)\n",
        "print(\"Run time for training the generator : {} seconds\".format(round(time()-start_time, 2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run time for training the generator : 1325.71 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCHOyNi7XEHH",
        "colab_type": "text"
      },
      "source": [
        "## Improved Comments generated by AutoBot using POS-Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nyEOkEfUX46f",
        "outputId": "6ac2d370-b94b-4488-b424-cd3b26f6b499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "generate_comments(comments_generator_POSified)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comment 1\n",
            "It is so scared of dying in the Oval Office\n",
            "\n",
            "Comment 2\n",
            "Let 's see if there is plenty of voter suppression efforts like Crosscheck , the sick , and to him .\n",
            "\n",
            "Comment 3\n",
            "This is a walking void of   national tragedy is the dumbest doctor in the middle of the ferocity of counter attacks by the Mueller probe .\n",
            "\n",
            "Comment 4\n",
            "Amy , if Stormy could be up in arms about this ?\n",
            "\n",
            "Comment 5\n",
            "I note one more sentimental commentator portraying Ryan as Vice President Mike Pence in that regard .\n",
            "\n",
            "Comment 6\n",
            "Just register Democrats and Republicans .\n",
            "\n",
            "Comment 7\n",
            "Germany is having difficulty understanding exactly what attorney client privilege with regard to politics .\n",
            "\n",
            "Comment 8\n",
            "Vote in November , and the public to special interests .\n",
            "\n",
            "Comment 9\n",
            "One can only imagine how they knew that these were the pawns in a very expensive health care free for all the money he raised on Social Security and Medicare by manufacturing a plethora of philippics , thru his stupidity , and preserve a treasonous president .\n",
            "\n",
            "Comment 10\n",
            "Trump is charging the wealth of information ” on everyone , you know that it had been a dozen republican candidates .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}